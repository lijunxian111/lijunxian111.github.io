<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Junxian Li</title>

    <meta name="author" content="Junxian Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Junxian Li
                </p>
                <p>I'm a Ph.D. student at <a href="http://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a>, shanghai, China.
                </p>
                <p>
                  I'm now advised by assistant prof. <a href="https://yulunzhang.com/group/">Yulun Zhang</a>. I'm working on MLLMs, unified models and model reasoning. I've been advised by prof. <a href="https://nsec.sjtu.edu.cn/~hjzhu/">Haojin Zhu</a> in 2024-2025. At Xi'an Jiaotong University I've worked on graph learning and data mining. I've worked as a remote research intern at DaRL Group with assistant prof. <a href = "https://labs.engineering.asu.edu/hw/">Hua Wei</a> for one year. 
			(also co-advised by assistant prof. <a href="https://gr.xjtu.edu.cn/en/web/shibin">Bin Shi</a>). 
                </p>
		<p style="text-align:center"> 
                Email:&nbsp  <b><span style="background: #d6eef8;"><code>ljx201806 [at] gmail [dot] com</code></span> &nbsp/&nbsp <span style="background: #d6eef8;"><code>lijunxian0531 [at] sjtu [dot] edu [dot] cn</code></span> &nbsp/&nbsp <span style="background: #d6eef8;"><code>ljx201806 [at] stu [dot] xjtu [dot] edu [dot] cn</code></span></b>
                </p>
                <p style="text-align:center">
                  <a href="mailto:ljx201806@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/JunxianLi-SJTU-1.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/ljx-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=U-b_eXkAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/lijunxian111">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/new.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/new.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research / <a href='https://scholar.google.com/citations?user=U-b_eXkAAAAJ'><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2Fgs_data_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Google Scholar Citations"></a></h2> 
                <p>
                  I'm interested in AI security, data mining and GNNs. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>ðŸ”¥What's New</heading>
              <div style="height: 120px; overflow: auto;">
		<ul>
		 <li> [2025.02] Our work "<a href="https://arxiv.org/abs/2411.18203" target="_blank">Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning</a>" was accepted to CVPR, 2025! ðŸŽ‰</li> 
                </ul> 
			<ul> 
		 <li> [2025.08] Our work "<a href="https://arxiv.org/abs/2412.19191" target="_blank">Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models</a>" was accepted to EMNLP Findings 2025! ðŸŽ‰</li> 
                </ul>
              </div>
            </td>
          </tr>
        </tbody></table>
	  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <h2>Conference papers</h2>

	<tr onmouseout="critic_v_stop()" onmouseover="critic_v_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='critic_v_image'></div>
          <img src='images/critic_v.png' width=100%>
        </div>
        <script type="text/javascript">
          function critic_v_start() {
            document.getElementById('critic_v_image').style.opacity = "1";
          }

          function critic_v_stop() {
            document.getElementById('critic_v_image').style.opacity = "0";
          }
          critic_v_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2411.18203">
                  <span class="papertitle">Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning</span>
                </a>
                <br>
		<a href="https://github.com/trotsky1997">Di Zhang*</a>,
	      	<a href="https://lijunxian111.github.io/"><strong>Junxian Li*</strong></a>,
	      	<a href="https://scholar.google.com/citations?user=dVyfBiQAAAAJ&hl=en&oi=ao">Jingdi Lei*</a>,
	        <a href="">Xunzhi Wang*</a>,
	        <a href="">Yujie Liu</a>,
	        <a href="">Zonglin Yang</a>,
	        <a href="">Jiatong Li</a>,
	        <a href="">Weida Wang</a>,
	        <a href="">Suorong Yang</a>,
	        <a href="">Jianbo Wu</a>,
	        <a href="">Peng Ye</a>,
	        <a href="">Wanli Ouyang</a>,
	        <a href="">Dongzhan Zhou</a>
                <br>
                <em>Proceedings of the Computer Vision and Pattern Recognition Conference, 9050-9061</em>
                <br>
                <a href="https://arxiv.org/abs/2411.18203">arXiv</a>
	        /
	       <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Critic-V_VLM_Critics_Help_Catch_VLM_Errors_in_Multimodal_Reasoning_CVPR_2025_paper.html">Conference Version</a>
	         <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U-b_eXkAAAAJ&citation_for_view=U-b_eXkAAAAJ:zA6iFVUQeVQC"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2FU-b_eXkAAAAJ:zA6iFVUQeVQC_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Citations"></a>
		<p></p>
                <p>We introduce Critic-V, a novel framework inspired by the Actor-Critic paradigm to boost the reasoning capability of VLMs.</p>
              </td>
    </tr>

	<tr onmouseout="ChemVLM_stop()" onmouseover="ChemVLM_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ChemVLM_image'></div>
          <img src='images/ChemVLM.png' width=100%>
        </div>
        <script type="text/javascript">
          function ChemVLM_start() {
            document.getElementById('ChemVLM_image').style.opacity = "1";
          }

          function ChemVLM_stop() {
            document.getElementById('ChemVLM_image').style.opacity = "0";
          }
          ChemVLM_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2408.07246">
                  <span class="papertitle">ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area</span>
                </a>
                <br>
		<a href="https://lijunxian111.github.io/"><strong>Junxian Li</strong></a>,
		<a href="https://github.com/trotsky1997">Di Zhang</a>,
	        <a href="">Xunzhi Wang</a>,
	        <a href="">Zeying Hao</a>,
	        <a href="https://scholar.google.com/citations?user=dVyfBiQAAAAJ&hl=en&oi=ao">Jingdi Lei</a>,
	        <a href="">Qian Tan</a>,
	        <a href="">Cai Zhou</a>,
	        <a href="">Wei Liu</a>,
	        <a href="">Yaotian Yang</a>,
	        <a href="">Xinrui Xiong</a>,
	        <a href="">Weiyun Wang</a>.
	        <a href="">Zhe Chen</a>,
	        <a href="">Wenhai Wang</a>,
	        <a href="">Wei Li</a>,
	        <a href="">Shufei Zhang</a>,
	        <a href="">Mao Su</a>,
	        <a href="">Wanli Ouyang</a>,
	        <a href="">Yuqiang Li</a>,
	        <a href="">Dongzhan Zhou</a>
                <br>
                <em>Proceedings of the AAAI conference on artificial intelligence, 2025</em>
                <br>
	         <a href="https://github.com/AI4Chem/ChemVlm">project page</a>
                /
                <a href="https://arxiv.org/abs/2408.07246">arXiv</a>
	        /
	        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32020">Conference Version</a>
	         <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U-b_eXkAAAAJ&citation_for_view=U-b_eXkAAAAJ:CHSYGLWDkRkC"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2FU-b_eXkAAAAJ:CHSYGLWDkRkC_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Citations"></a>
	        <a href="https://github.com/lijunxian111/ChemVlm"><img src="https://img.shields.io/github/stars/lijunxian111/ChemVlm"></a>
		<p></p>
                <p>We propose ChemVLM, an open-source multimodal large language model for chemical tasks.</p>
              </td>
    </tr>


	<tr onmouseout="uncer_stop()" onmouseover="uncer_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='uncer_image'></div>
          <img src='images/uncer_tra.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function uncer_start() {
            document.getElementById('uncer_image').style.opacity = "1";
          }

          function uncer_stop() {
            document.getElementById('uncer_image').style.opacity = "0";
          }
          uncer_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/lijunxian111/UIGNN">
                  <span class="papertitle">Uncertainty-aware Traffic Prediction under Missing Data</span>
                </a>
                <br>
                <a href="">Hao Mei</a>,
		<a href="https://lijunxian111.github.io/"><strong>Junxian Li</strong></a>,
		<a href="">Zhiming Liang</a>,
		<a href="https://jhc.sjtu.edu.cn/~gjzheng/">Guanjie Zheng</a>,
		<a href="https://gr.xjtu.edu.cn/en/web/shibin/home">Bin Shi</a>,
	        <a href="https://labs.engineering.asu.edu/hw/">Hua Wei*</a>
                <br>
                <em>23rd IEEE International Conference on Data Mining (ICDM)</em>, 2023
                <br>
		<a href="https://github.com/lijunxian111/UIGNN">project page</a>
                /
                <a href="https://arxiv.org/abs/2309.06800">arXiv</a>
	        /
	        <a href="https://ieeexplore.ieee.org/abstract/document/10415744">Conference Version</a>
	        /
	        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U-b_eXkAAAAJ&citation_for_view=U-b_eXkAAAAJ:fPk4N6BV_jEC"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2FU-b_eXkAAAAJ:fPk4N6BV_jEC_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Citations"></a>
		<p></p>
                <p>Uncertainty quantification (like dropout and evidential deep learning) can be used for better sensor deployment on spatio-temporal traffic prediction.</p>
              </td>
    </tr>
			  
    <tr onmouseout="RL_Mis_stop()" onmouseover="RL_mis_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='RL_Mis_image'><!-- <video  width=100% muted autoplay loop>
          <source src="images/smerf.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video> --></div>
          <img src='images/RL_Mis.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function RL_Mis_start() {
            document.getElementById('RL_Mis_image').style.opacity = "1";
          }

          function RL_Mis_stop() {
            document.getElementById('RL_Mis_image').style.opacity = "0";
          }
          RL_Mis_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/derekmei233/MissLight">
          <span class="papertitle">Reinforcement Learning Approaches for Traffic Signal Control under Missing Data</span>
        </a>
        <br>
		<a href="">Hao Mei</a>,
		<a href="https://lijunxian111.github.io/"><strong>Junxian Li</strong></a>,
		<a href="https://gr.xjtu.edu.cn/en/web/shibin/home">Bin Shi</a>,
	<a href="https://labs.engineering.asu.edu/hw/">Hua Wei*</a>
        <br>
        <em>International Joint Conferences on Artifical Intelligence(IJCAI)</em>, 2023
        <br>
        <a href="https://github.com/derekmei233/MissLight">project page</a>
        /
        <a href="https://arxiv.org/abs/2304.10722">arXiv</a>
	/
	<a href="https://www.ijcai.org/proceedings/2023/0251.pdf">Conference Version</a>
	/
	<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U-b_eXkAAAAJ&citation_for_view=U-b_eXkAAAAJ:M3ejUd6NZC8C"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2FU-b_eXkAAAAJ:M3ejUd6NZC8C_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Citations"></a>
	<a href="https://github.com/derekmei233/MissLight"><img src="https://img.shields.io/github/stars/derekmei233/MissLight"></a>
        <p></p>
        <p>
        Using DQNs to solve traffic signal control problems under missing data scenario.
        </p>
      </td>
    </tr>


    
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <h2>Preprints</h2>
     <tr onmouseout="GNN_KD_stop()" onmouseover="GNN_KD_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='GNN_KD_image'></div>
          <img src='images/GNN_KD.png' width=100%>
        </div>
        <script type="text/javascript">
          function GNN_KD_start() {
            document.getElementById('GNN_KD_image').style.opacity = "1";
          }

          function GNN_KD_stop() {
            document.getElementById('GNN_KD_image').style.opacity = "0";
          }
          GNN_KD_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2403.01079">
                  <span class="papertitle">Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework</span>
                </a>
                <br>
		<a href="https://lijunxian111.github.io/"><strong>Junxian Li</strong></a>,
		<a href="https://gr.xjtu.edu.cn/en/web/shibin/home">Bin Shi*</a>,
	        <a href="https://scholar.google.com/citations?hl=en&user=MRTB_-wAAAAJ">Erfei Cui</a>,
	        <a href="https://labs.engineering.asu.edu/hw/">Hua Wei</a>
	        <a href="">Qinghua Zheng</a>
                <br>
                <em>Arxiv preprint arxiv</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2403.01079">arXiv</a>
	        /
	        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U-b_eXkAAAAJ&citation_for_view=U-b_eXkAAAAJ:Tyk-4Ss8FVUC"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2FU-b_eXkAAAAJ:Tyk-4Ss8FVUC_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Citations"></a>
		<p></p>
                <p>With position encoding and graph heat kernel learning, MLPs can learn topology knowledge of graphs and performance of knowledge distillation between GNNs and MLPs can be obviously improved.</p>
              </td>
    </tr>
		<tr onmouseout="Faith_stop()" onmouseover="Faith_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='faith_image'></div>
          <img src='images/faith.png' width=100%>
        </div>
        <script type="text/javascript">
          function Faith_start() {
            document.getElementById('faith_image').style.opacity = "1";
          }

          function Faith_stop() {
            document.getElementById('faith_image').style.opacity = "0";
          }
          GNN_KD_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2511.08409">
                  <span class="papertitle">FaithAct: Faithfulness Planning and Acting in MLLMs</span>
                </a>
                <br>
		<a href="https://lijunxian111.github.io/"><strong>Junxian Li</strong></a>,
		<a href="">Xinyue Xu</a>,
	        <a href="">Sai Ma</a>
	        <a href="https://sichao-li.github.io/">Sichao Li</a>
                <br>
                <em>Arxiv preprint arxiv</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2511.08409">arXiv</a>
	        /
	        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U-b_eXkAAAAJ&citation_for_view=U-b_eXkAAAAJ:JoZmwDi-zQgC"><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Flijunxian111%2Flijunxian111.github.io@google-scholar-stats%2FU-b_eXkAAAAJ:JoZmwDi-zQgC_shieldsio.json&labelColor=ffffff&color=5383ec&style=plastic&label=Citations"></a>
		<p></p>
                <p>We introduce FaithEval and FaithAct, a unified framework that evaluates and enforces step-level perceptual faithfulness in multimodal reasoning, significantly improving grounding and stability without sacrificing task performance.</p>
              </td>
    </tr>
            
          </tbody></table>

	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Education</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="90%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/XJTU.png" width="70%" ></td>
              <td width="75%" valign="center">
                <b>Xi'an Jiaotong University</b>
                <br> 2020.09 - 2024.07<br>
                <br> <b>B.E. in Computer Science and Technology</b>
                <br> GPA: 94.27 (+2) / 100.0 [top 1.5%]
                <br> Advisor: Assistant Prof. <a href="https://gr.xjtu.edu.cn/en/web/shibin">Bin Shi</a>
              </td>
            </tr>
	  </tbody></table>

          <table width="90%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/SJTU.jpg" width="70%" ></td>
              <td width="75%" valign="center">
                <b>Shanghai Jiaotong University</b>
                <br> 2024.09-<br>
                <br> <b>Postgraduate in Computer Science and Technology</b>
                <br> Advisor: Prof. <a href="https://nsec.sjtu.edu.cn/~hjzhu/">Haojin Zhu</a>
              </td>
            </tr>
	  </tbody></table>
		
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Honors&Awards</h2>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>

              <tr>
                <td width="75%" valign="center">
                  <li>China 'Internet+' competition, <strong>National gold medal</strong>, 2022</li>
                  <li>Kaggle: LLM AI generated_detection, Bronze medal<strong>(218/4231)</strong>, 2024</li>
                  <li>China Guanggu scholarship, Xi'an Jiaotong University, 2021-2022<strong>(1/190+ won this sholarship)</strong></li>
                  <li>Scholarship for Outstanding Students, First Prize, Xi'an Jiaotong University, 2020-2021, 2022-2023</li>
                </td>
              </tr>
	  </tbody></table>

	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Services&Academic Experiences</h2>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>

              <tr>
                <td width="75%" valign="center">
                  <li>Reviewer: IJCAI, KDD, ACL ARR, AAAI, CVPR, ICML</li>
                </td>
              </tr>
	  </tbody></table>
		
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Hobbies</h2>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>
         <iframe allow="autoplay *; encrypted-media *; fullscreen *; clipboard-write" frameborder="0" height="450" style="width:100%;max-width:660px;overflow:hidden;border-radius:10px;" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation" src="https://embed.music.apple.com/cn/album/%E5%9C%A8%E9%A9%9A%E6%BF%A4%E9%A7%AD%E6%B5%AA%E8%A3%A1-%E5%A4%A7%E5%9E%8B%E7%B4%80%E9%8C%84%E7%89%87-%E7%B4%AB%E7%A6%81%E5%9F%8E-%E4%B8%BB%E9%A1%8C%E6%AD%8C-single/1586975039"></iframe>
	 <!-- <iframe allow="autoplay *; encrypted-media *; fullscreen *; clipboard-write" frameborder="0" height="175" style="width:100%;max-width:660px;overflow:hidden;border-radius:10px;" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation" src="https://embed.music.apple.com/cn/album/%E8%BD%AC%E7%9C%BC-2018%E8%87%AA%E4%BC%A0%E6%9C%80%E7%BB%88%E7%AB%A0/1448026221?i=1448026222"></iframe> -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/lijunxian111/lijunxian111.github.io">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
